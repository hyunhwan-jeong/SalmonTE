import sys
from os.path import join

INDEX = config["index"]
INPUT_DIR = config["input_path"]
OUTPUT_DIR = config["output_path"]
SALMON_PATH = config["salmon"].format(sys.platform)
NUM_THREADS = str(config["num_threads"])
EXPR_TYPE = config["exprtype"]
SAMPLES_FQ = glob_wildcards(join(INPUT_DIR, "{sample}.fastq")).sample
SAMPLES_GZ = glob_wildcards(join(INPUT_DIR, "{sample}.fastq.gz")).sample

rule all:
    input:
        join(OUTPUT_DIR,"EXPR.csv"),
        join(OUTPUT_DIR,"MAPPING_INFO.csv")

rule run_salmon_fq:
    input:
        idx = INDEX,
        r = join(INPUT_DIR,"{sample_fq}.fastq")
    
    output:
        directory(join(OUTPUT_DIR,"{sample_fq}"))

    shell:
        SALMON_PATH + " quant -i {input.idx} -l A -r {input.r} -o {output} -p " + NUM_THREADS + " 2>/dev/null"


rule run_salmon_gz:
    input:
        idx = INDEX,
        r = join(INPUT_DIR,"{sample_gz}.fastq.gz")
    
    output:
        directory(join(OUTPUT_DIR,"{sample_gz}"))

    shell:
        SALMON_PATH + " quant -i {input.idx} -l A -r {input.r} -o {output} -p " + NUM_THREADS + " 2>/dev/null"


rule collect_abundance:
    input:
        expand(join(OUTPUT_DIR,"{sample_fq}"), sample_fq = SAMPLES_FQ) +
        expand(join(OUTPUT_DIR,"{sample_gz}"), sample_gz = SAMPLES_GZ) 
    output:
        join(OUTPUT_DIR,"EXPR.csv")
    run:
        def get_abundance(fname):
            from collections import defaultdict
            abundance = defaultdict( float )
            with open(fname, "r") as inp:
                line = inp.readline()
                for line in inp:
                    line = line.strip().split()
                    name = line[0]
                    abundance[name] += float(line[3]) if EXPR_TYPE == "TPM" else float(line[-1])

            return abundance

        tb = dict()
        for file in input:
            file = join(file, "quant.sf")
            sid = file.split("/")[-2]
            tb[sid] = get_abundance(file) 

        import pandas as pd
        with open(str(output), "w") as oup:
            oup.write(pd.DataFrame(tb).to_csv(sep=",", index_label="TE"))


rule collect_mappability:
    input:
        expand(join(OUTPUT_DIR,"{sample_fq}"), sample_fq = SAMPLES_FQ) +
        expand(join(OUTPUT_DIR,"{sample_gz}"), sample_gz = SAMPLES_GZ) 
    output:
        join(OUTPUT_DIR,"MAPPING_INFO.csv")
    run:
        def get_mappability(fname):
            import json
            from collections import defaultdict
            with open(fname, "r") as inp:
                data = json.load(inp)
            sid = file.split("/")[-3]
            return { 
                "SampleID" : sid, 
                "num_mapped": data["num_mapped"], 
                "num_processed" : data["num_processed"], 
                "percent_mapped": data["percent_mapped"] }
        tb = []
        for file in input:
            file = join(file, "aux_info/meta_info.json")
            tb.append(get_mappability(file))

        import pandas as pd
        with open(str(output), "w") as oup:
            oup.write(pd.DataFrame(tb).set_index("SampleID").to_csv(sep=",", index_label="SampleID"))
